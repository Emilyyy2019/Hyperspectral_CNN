{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import random\n",
    "import spectral\n",
    "import scipy.ndimage\n",
    "from skimage.transform import rotate\n",
    "import os\n",
    "# import patch_size\n",
    "patch_size = 21 \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Indian Pines Data (Numpy Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix Type: <class 'numpy.ndarray'>\n",
      "Target Matrix Type: <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "Input Matrix: (145, 145, 200)\n",
      "Target Matrix: (145, 145, 200)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(),\"IndianPines\")\n",
    "NEW_DATA_PATH = os.path.join(os.getcwd(),\"new_indian_pines_data\")\n",
    "input_mat = scipy.io.loadmat(os.path.join(DATA_PATH, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "target_mat = scipy.io.loadmat(os.path.join(DATA_PATH, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "\n",
    "print(\"Input Matrix Type: %s\" %type(input_mat))\n",
    "print(\"Target Matrix Type: %s\" %type(input_mat))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Input Matrix: %s\" %str(np.shape(input_mat)))\n",
    "print(\"Target Matrix: %s\" %str(np.shape(input_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Now let us define our global variables that define our data\n",
    "HEIGHT = input_mat.shape[0]\n",
    "WIDTH = input_mat.shape[1]\n",
    "BAND = input_mat.shape[2]\n",
    "print(BAND)\n",
    "PATCH_SIZE = patch_size\n",
    "TRAIN_PATCH, TRAIN_LABELS, TEST_PATCH, TEST_LABELS, CLASSES = [],[],[],[],[]\n",
    "COUNT =200 # Number of patches of each class (This will change depending on the selected patch size)\n",
    "OUTPUT_CLASSES = 16\n",
    "TEST_FRAC = 0.25 # percentage used for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling input between [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mat =input_mat.astype(float) # change elements in the tensor to float\n",
    "input_mat -= np.min(input_mat) # shift [0 to max]\n",
    "input_mat /= np.max(input_mat) # scale ([0 to max])/max = [0 to 1] array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.231513871206\n",
      "0.362622411449\n",
      "0.38414871768\n",
      "0.37171426415\n",
      "0.411802366546\n",
      "0.443472672983\n",
      "0.450146557326\n",
      "0.434701411599\n",
      "0.429402801201\n",
      "0.402828713264\n",
      "0.399143551886\n",
      "0.387621902087\n",
      "0.369221490419\n",
      "0.398366819915\n",
      "0.406516222793\n",
      "0.403828316086\n",
      "0.385139329339\n",
      "0.360198778934\n",
      "0.348285917323\n",
      "0.336018902888\n",
      "0.332833259713\n",
      "0.330136521319\n",
      "0.322258079639\n",
      "0.312484245874\n",
      "0.311774405954\n",
      "0.301452661185\n",
      "0.288851235989\n",
      "0.292987412785\n",
      "0.29031911616\n",
      "0.265439480195\n",
      "0.294790022669\n",
      "0.262392190941\n",
      "0.295587519551\n",
      "0.346116572486\n",
      "0.372140879696\n",
      "0.403517656293\n",
      "0.503496657666\n",
      "0.577634573578\n",
      "0.576080559718\n",
      "0.367975513242\n",
      "0.594116370116\n",
      "0.607950239001\n",
      "0.578010882606\n",
      "0.570455099935\n",
      "0.522339934964\n",
      "0.469485789357\n",
      "0.504717745544\n",
      "0.554142375748\n",
      "0.545172225446\n",
      "0.546258973806\n",
      "0.538296455131\n",
      "0.542029893829\n",
      "0.529045654072\n",
      "0.415637644596\n",
      "0.390610933006\n",
      "0.378519534951\n",
      "0.313514990564\n",
      "0.15830015883\n",
      "0.175973930578\n",
      "0.202181602514\n",
      "0.260398138032\n",
      "0.351874370086\n",
      "0.411255945819\n",
      "0.44522874329\n",
      "0.434213491171\n",
      "0.436907628452\n",
      "0.430471176793\n",
      "0.428374828099\n",
      "0.423353453466\n",
      "0.419090570016\n",
      "0.402945785351\n",
      "0.393065426931\n",
      "0.382662860683\n",
      "0.359903313381\n",
      "0.280965155945\n",
      "0.226154830296\n",
      "0.095855544186\n",
      "0.0760120371596\n",
      "0.107290873324\n",
      "0.0959139674963\n",
      "0.153930035831\n",
      "0.21911851686\n",
      "0.230755682477\n",
      "0.228868423683\n",
      "0.234156871592\n",
      "0.231964221222\n",
      "0.236897092019\n",
      "0.237293110116\n",
      "0.237808377976\n",
      "0.2367392215\n",
      "0.237648478259\n",
      "0.214206196506\n",
      "0.221285029618\n",
      "0.233338455821\n",
      "0.214593437909\n",
      "0.231308482255\n",
      "0.229654069828\n",
      "0.210680758871\n",
      "0.176353742585\n",
      "0.15061091101\n",
      "0.100443456791\n",
      "0.0670797927193\n",
      "0.0153616461472\n",
      "0.00938884152718\n",
      "0.0116263762219\n",
      "0.0143135955316\n",
      "0.0162140743591\n",
      "0.0261501449928\n",
      "0.03367570416\n",
      "0.0275621204791\n",
      "0.0363198098823\n",
      "0.0583094936917\n",
      "0.0785857643499\n",
      "0.0934182846979\n",
      "0.104668285901\n",
      "0.110852490078\n",
      "0.114954857902\n",
      "0.11691019107\n",
      "0.116603925124\n",
      "0.107369715097\n",
      "0.109162992869\n",
      "0.113173298886\n",
      "0.110021783635\n",
      "0.109715231731\n",
      "0.11536357361\n",
      "0.115576875884\n",
      "0.110458649657\n",
      "0.108743465769\n",
      "0.108494523296\n",
      "0.10463622017\n",
      "0.102769022393\n",
      "0.09874100351\n",
      "0.094400779564\n",
      "0.0893804112811\n",
      "0.0856816119312\n",
      "0.0786528048784\n",
      "0.0735934858889\n",
      "0.0703136692206\n",
      "0.0651293428244\n",
      "0.0552243260718\n",
      "0.0423647087791\n",
      "0.031888629465\n",
      "0.017654761075\n",
      "0.0096772461306\n",
      "0.00736250291972\n",
      "0.00841147739788\n",
      "0.0128584019734\n",
      "0.0212159983854\n",
      "0.0271222739008\n",
      "0.0232200378096\n",
      "0.0125953046059\n",
      "0.0129536478068\n",
      "0.0219321678642\n",
      "0.0308264129564\n",
      "0.0300424385628\n",
      "0.024154332345\n",
      "0.0241278152891\n",
      "0.0277910184334\n",
      "0.0325620043089\n",
      "0.0339344571737\n",
      "0.0346855959512\n",
      "0.0345581799027\n",
      "0.0345241014715\n",
      "0.0346138041293\n",
      "0.0340026580297\n",
      "0.0322952884795\n",
      "0.0315723165126\n",
      "0.0314070056005\n",
      "0.0309964366675\n",
      "0.0303240626747\n",
      "0.0296522715953\n",
      "0.0309830846534\n",
      "0.0308257035619\n",
      "0.0296662450169\n",
      "0.0282730767332\n",
      "0.0265700460378\n",
      "0.025405099309\n",
      "0.0244311666693\n",
      "0.0239127037842\n",
      "0.0224959605071\n",
      "0.0223245070086\n",
      "0.0217842783609\n",
      "0.0205063069432\n",
      "0.0204211301122\n",
      "0.0182527146369\n",
      "0.0171443709891\n",
      "0.0173976193216\n",
      "0.0154698260567\n",
      "0.0145027014044\n",
      "0.0145579571858\n",
      "0.0143728492183\n",
      "0.0123630301538\n",
      "0.0121644436911\n",
      "0.0125189979555\n",
      "0.0109895379436\n",
      "0.0098509817896\n",
      "0.010217403289\n",
      "0.00869404736913\n",
      "0.00700329084803\n",
      "0.00618725622298\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean of each channel for normalization\n",
    "MEAN_ARRAY = np.ndarray(shape=(BAND,),dtype=float) #row vector containing the mean of each batch\n",
    "for i in range(BAND):\n",
    "    MEAN_ARRAY[i] = np.mean(input_mat[:,:,i]) # mean per band\n",
    "    print(MEAN_ARRAY[i])\n",
    "#np.transpose(input_mat, (2,0,1)).shape transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch(height_index, width_index):\n",
    "    \"\"\"\n",
    "    Returns a mean-normalized patch, the top left corner of which \n",
    "    is at (height_index, width_index)\n",
    "    \n",
    "    Inputs: \n",
    "    height_index - row index of the top left corner of the image patch\n",
    "    width_index - column index of the top left corner of the image patch\n",
    "    \n",
    "    Outputs:\n",
    "    mean_normalized_patch - mean normalized patch of size (PATCH_SIZE, PATCH_SIZE) \n",
    "    whose top left corner is at (height_index, width_index)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # creating patch slices\n",
    "    transposed_array = np.transpose(input_mat, (2,0,1))\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    transposed_patch = transposed_array[:,height_slice,width_slice]\n",
    "    mean_normalized_patch = []\n",
    "    for i in range(transposed_patch.shape[0]): # for every band normalize patch\n",
    "        mean_normalized_patch.append(transposed_patch[i]-MEAN_ARRAY[i]) # substract the mean for every element of in the matrix\n",
    "    return np.array(mean_normalized_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain all patches and separate them by class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "CLASSES = []\n",
    "for classes in range(OUTPUT_CLASSES):\n",
    "    CLASSES.append([]) # append the number of list classes \n",
    "    \n",
    "    \n",
    "# getting patches\n",
    "\n",
    "for i in range(HEIGHT - PATCH_SIZE +1):\n",
    "    for j in range(WIDTH - PATCH_SIZE +1):\n",
    "        # the actual patch tensor\n",
    "        input_img = patch(i,j)\n",
    "        #choose the middle of the patch as classification\n",
    "        target_id = target_mat[i+int((PATCH_SIZE-1)/2),j+int((PATCH_SIZE-1)/2)]\n",
    "        if(target_id != 0): # ignore the UNKNOWN patches\n",
    "            CLASSES[target_id -1].append(input_img)\n",
    "            \n",
    "print(\"Done\")\n",
    "print(type(CLASSES[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 145, 200)\n",
      "(145, 145)\n",
      "16\n",
      "(46, 200, 21, 21)\n",
      "\n",
      "\n",
      "Class 1 contains: 46 patches\n",
      "Class 2 contains: 1378 patches\n",
      "Class 3 contains: 547 patches\n",
      "Class 4 contains: 152 patches\n",
      "Class 5 contains: 340 patches\n",
      "Class 6 contains: 730 patches\n",
      "Class 7 contains: 28 patches\n",
      "Class 8 contains: 356 patches\n",
      "Class 9 contains: 20 patches\n",
      "Class 10 contains: 843 patches\n",
      "Class 11 contains: 2245 patches\n",
      "Class 12 contains: 481 patches\n",
      "Class 13 contains: 205 patches\n",
      "Class 14 contains: 1095 patches\n",
      "Class 15 contains: 142 patches\n",
      "Class 16 contains: 93 patches\n"
     ]
    }
   ],
   "source": [
    "print(input_mat.shape)\n",
    "print(target_mat.shape)\n",
    "print(len(CLASSES))\n",
    "print(np.array(CLASSES[0]).shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "for c in range(len(CLASSES)):\n",
    "    print(\"Class %d contains: %s patches\"%(c+1,len(CLASSES[c])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract 25% from data set for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "1034\n",
      "411\n",
      "114\n",
      "255\n",
      "548\n",
      "21\n",
      "267\n",
      "15\n",
      "633\n",
      "1684\n",
      "361\n",
      "154\n",
      "822\n",
      "107\n",
      "70\n",
      "____________\n",
      "16\n",
      "2170\n",
      "____________\n",
      "(35, 200, 21, 21)\n",
      "(200, 21, 21)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(CLASSES)):\n",
    "    class_population = len(CLASSES[i])\n",
    "    split_size = int(class_population*TEST_FRAC) # getting 25% (spliting size for the test)\n",
    "    patches_class = CLASSES[i] # extracting patches from class\n",
    "    shuffle(patches_class) # shuffling patches\n",
    "    TRAIN_PATCH.append(patches_class[:-split_size]) # from 0 to (len -split_size) contains patches\n",
    "    TEST_PATCH.extend(patches_class[-split_size:]) # from split_size to len(class)-1\n",
    "    TEST_LABELS.extend(np.full(split_size,i,dtype=int)) # 0 to 15 label\n",
    "\n",
    "for c in TRAIN_PATCH:\n",
    "    print(len(c))\n",
    "print(\"____________\")\n",
    "\n",
    "print(len(TRAIN_PATCH))\n",
    "print(len(TEST_PATCH))\n",
    "print(\"____________\")\n",
    "print(np.shape(TRAIN_PATCH[0]))\n",
    "print(np.shape(TEST_PATCH[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = CLASSES[0]\n",
    "#print(int(len(x)*TEST_FRAC))\n",
    "#print(np.shape(x))\n",
    "#np.shape(x[:-int(class_population*TEST_FRAC)])\n",
    "#np.full(int(len(x)*TEST_FRAC),len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversample the classes which do not have at least COUNT patches in the training set and extract COUNT patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This methods ensures that there are at least COUNT samples for every class\n",
    "for i in range(len(TRAIN_PATCH)):\n",
    "    if(len(TRAIN_PATCH[i])<COUNT):\n",
    "        temp = TRAIN_PATCH[i]\n",
    "        for j in range(int(COUNT/len(TRAIN_PATCH[i]))):\n",
    "            shuffle(TRAIN_PATCH[i])\n",
    "            TRAIN_PATCH[i] = TRAIN_PATCH[i]+temp # adding oversamples to the TRAININ_PATCH\n",
    "    shuffle(TRAIN_PATCH[i])\n",
    "    TRAIN_PATCH[i] = TRAIN_PATCH[i][:COUNT] # include all new oversamples of at most COUNT\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# Checking the code from above\n",
    "for c in range(len(TRAIN_PATCH)):\n",
    "    print(len(TRAIN_PATCH[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 200, 200, 21, 21)\n",
      "(3200, 200, 21, 21)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATCH = np.asarray(TRAIN_PATCH)\n",
    "print(np.shape(TRAIN_PATCH))\n",
    "TRAIN_PATCH = TRAIN_PATCH.reshape((-1,200,PATCH_SIZE,PATCH_SIZE)) # reduce dimension of the training tensor\n",
    "print(np.shape(TRAIN_PATCH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of training labels is: 3200\n",
      "The length of testing labels is: 2170\n"
     ]
    }
   ],
   "source": [
    "TRAINING_LABELS = np.array([])\n",
    "for i in range(OUTPUT_CLASSES):\n",
    "    TRAINING_LABELS = np.append(TRAINING_LABELS,np.full(COUNT,i,dtype=int))\n",
    "print(\"The length of training labels is: %d\"%len(TRAINING_LABELS))\n",
    "print(\"The length of testing labels is: %d\"%len(TEST_LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "l_train = int(len(TRAIN_PATCH)/(COUNT))\n",
    "l_testing = int(len(TEST_PATCH)/(COUNT))\n",
    "for i in range(l_train):\n",
    "    train_dict ={}\n",
    "    start = i*COUNT\n",
    "    end = (i+1)*COUNT\n",
    "    train_dict[\"train_patches\"] = TRAIN_PATCH[start:end]\n",
    "    train_dict[\"train_labels\"] = TRAIN_LABELS[start:end]\n",
    "    file_name = \"Training(%s)_class(%d).mat\"%(str(PATCH_SIZE),i)\n",
    "    scipy.io.savemat(os.path.join(NEW_DATA_PATH,file_name),train_dict)\n",
    "\n",
    "for i in range(l_testing):\n",
    "    test_dict = {}\n",
    "    start = i*COUNT\n",
    "    end = (i+1)*COUNT\n",
    "    test_dict[\"testing_patches\"] = TEST_PATCH[start:end]\n",
    "    test_dict[\"testing_labels\"] = TEST_LABELS[start:end]\n",
    "    file_name = \"Testing(%s)_class(%d).mat\"%(str(PATCH_SIZE),i)\n",
    "    scipy.io.savemat(os.path.join(NEW_DATA_PATH,file_name),test_dict)\n",
    "print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
