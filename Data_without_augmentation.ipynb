{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import random\n",
    "#import spectral\n",
    "import scipy.ndimage\n",
    "#from skimage.transform import rotate\n",
    "import os\n",
    "# import patch_size\n",
    "patch_size = 21 \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Indian Pines Data (Numpy Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix Type: <class 'numpy.ndarray'>\n",
      "Target Matrix Type: <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "Input Matrix: (145, 145, 200)\n",
      "Target Matrix: (145, 145, 200)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(),\"IndianPines\")\n",
    "NEW_DATA_PATH = os.path.join(os.getcwd(),\"new_indian_pines_data\")\n",
    "input_mat = scipy.io.loadmat(os.path.join(DATA_PATH, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "target_mat = scipy.io.loadmat(os.path.join(DATA_PATH, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "\n",
    "print(\"Input Matrix Type: %s\" %type(input_mat))\n",
    "print(\"Target Matrix Type: %s\" %type(input_mat))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Input Matrix: %s\" %str(np.shape(input_mat)))\n",
    "print(\"Target Matrix: %s\" %str(np.shape(input_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Now let us define our global variables that define our data\n",
    "HEIGHT = input_mat.shape[0]\n",
    "WIDTH = input_mat.shape[1]\n",
    "BAND = input_mat.shape[2]\n",
    "print(BAND)\n",
    "PATCH_SIZE = patch_size\n",
    "TRAIN_PATCH, TRAIN_LABELS, TEST_PATCH, TEST_LABELS, CLASSES = [],[],[],[],[]\n",
    "COUNT =200 # Number of patches of each class (This will change depending on the selected patch size)\n",
    "OUTPUT_CLASSES = 16\n",
    "TEST_FRAC = 0.25 # percentage used for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling input between [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mat =input_mat.astype(float) # change elements in the tensor to float\n",
    "input_mat -= np.min(input_mat) # shift [0 to max]\n",
    "input_mat /= np.max(input_mat) # scale ([0 to max])/max = [0 to 1] array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2315138712055816\n",
      "0.36262241144907714\n",
      "0.38414871768010406\n",
      "0.37171426414963604\n",
      "0.4118023665455059\n",
      "0.4434726729833022\n",
      "0.45014655732642966\n",
      "0.43470141159879233\n",
      "0.42940280120085644\n",
      "0.40282871326426084\n",
      "0.3991435518859513\n",
      "0.38762190208733827\n",
      "0.3692214904185689\n",
      "0.39836681991512285\n",
      "0.4065162227933123\n",
      "0.4038283160858362\n",
      "0.3851393293390024\n",
      "0.3601987789341183\n",
      "0.3482859173233721\n",
      "0.3360189028884316\n",
      "0.3328332597130334\n",
      "0.3301365213191603\n",
      "0.3222580796388797\n",
      "0.3124842458744792\n",
      "0.31177440595429434\n",
      "0.30145266118480707\n",
      "0.2888512359892871\n",
      "0.2929874127846909\n",
      "0.2903191161604601\n",
      "0.26543948019531444\n",
      "0.2947900226690033\n",
      "0.26239219094149985\n",
      "0.29558751955131074\n",
      "0.34611657248629984\n",
      "0.3721408796959062\n",
      "0.4035176562925973\n",
      "0.5034966576658805\n",
      "0.5776345735776125\n",
      "0.576080559717749\n",
      "0.36797551324209915\n",
      "0.5941163701163998\n",
      "0.6079502390013266\n",
      "0.5780108826063484\n",
      "0.5704550999345734\n",
      "0.5223399349639233\n",
      "0.4694857893574055\n",
      "0.5047177455443221\n",
      "0.5541423757483872\n",
      "0.5451722254461178\n",
      "0.5462589738058836\n",
      "0.5382964551310049\n",
      "0.5420298938286667\n",
      "0.5290456540720275\n",
      "0.41563764459583696\n",
      "0.39061093300635197\n",
      "0.37851953495067026\n",
      "0.313514990564091\n",
      "0.15830015883012602\n",
      "0.17597393057750074\n",
      "0.20218160251389608\n",
      "0.26039813803194445\n",
      "0.35187437008587935\n",
      "0.4112559458187588\n",
      "0.44522874328979495\n",
      "0.434213491170857\n",
      "0.4369076284516132\n",
      "0.43047117679334174\n",
      "0.4283748280990056\n",
      "0.4233534534657151\n",
      "0.4190905700163422\n",
      "0.40294578535125136\n",
      "0.39306542693106183\n",
      "0.38266286068275923\n",
      "0.35990331338092596\n",
      "0.2809651559451176\n",
      "0.2261548302959289\n",
      "0.09585554418599664\n",
      "0.07601203715962297\n",
      "0.10729087332372901\n",
      "0.09591396749625954\n",
      "0.15393003583129553\n",
      "0.2191185168595986\n",
      "0.2307556824766776\n",
      "0.2288684236828325\n",
      "0.23415687159231152\n",
      "0.23196422122164603\n",
      "0.2368970920187759\n",
      "0.23729311011603407\n",
      "0.2378083779763807\n",
      "0.23673922150004215\n",
      "0.2376484782594649\n",
      "0.2142061965058472\n",
      "0.2212850296179072\n",
      "0.2333384558214273\n",
      "0.21459343790852908\n",
      "0.23130848225462067\n",
      "0.229654069827789\n",
      "0.2106807588706275\n",
      "0.17635374258521225\n",
      "0.1506109110096237\n",
      "0.1004434567913455\n",
      "0.06707979271933041\n",
      "0.015361646147156186\n",
      "0.009388841527183351\n",
      "0.011626376221866701\n",
      "0.014313595531584622\n",
      "0.016214074359115014\n",
      "0.026150144992809134\n",
      "0.03367570415995251\n",
      "0.02756212047910524\n",
      "0.036319809882277634\n",
      "0.05830949369168203\n",
      "0.078585764349875\n",
      "0.09341828469787976\n",
      "0.10466828590082583\n",
      "0.11085249007775706\n",
      "0.11495485790182282\n",
      "0.11691019107045565\n",
      "0.11660392512368693\n",
      "0.10736971509700077\n",
      "0.10916299286934811\n",
      "0.11317329888645687\n",
      "0.1100217836349566\n",
      "0.10971523173072045\n",
      "0.1153635736104701\n",
      "0.11557687588442316\n",
      "0.1104586496565967\n",
      "0.10874346576876023\n",
      "0.10849452329584129\n",
      "0.10463622017020244\n",
      "0.10276902239253188\n",
      "0.09874100350999043\n",
      "0.09440077956404958\n",
      "0.08938041128107709\n",
      "0.08568161193124538\n",
      "0.07865280487843439\n",
      "0.07359348588889261\n",
      "0.07031366922062429\n",
      "0.06512934282437167\n",
      "0.0552243260718009\n",
      "0.042364708779127964\n",
      "0.031888629464974956\n",
      "0.017654761074974608\n",
      "0.00967724613060365\n",
      "0.007362502919721977\n",
      "0.008411477397880533\n",
      "0.012858401973436477\n",
      "0.021215998385440145\n",
      "0.027122273900785678\n",
      "0.02322003780962629\n",
      "0.012595304605881182\n",
      "0.012953647806809335\n",
      "0.0219321678641823\n",
      "0.0308264129564029\n",
      "0.030042438562794264\n",
      "0.024154332344992837\n",
      "0.024127815289073443\n",
      "0.027791018433395764\n",
      "0.03256200430888411\n",
      "0.03393445717367613\n",
      "0.03468559595117221\n",
      "0.03455817990271672\n",
      "0.03452410147145739\n",
      "0.03461380412930832\n",
      "0.034002658029651314\n",
      "0.032295288479529775\n",
      "0.03157231651257271\n",
      "0.031407005600504495\n",
      "0.03099643666750117\n",
      "0.030324062674727915\n",
      "0.0296522715952536\n",
      "0.030983084653446357\n",
      "0.03082570356191645\n",
      "0.029666245016881802\n",
      "0.028273076733249386\n",
      "0.02657004603777745\n",
      "0.025405099309041522\n",
      "0.02443116666934752\n",
      "0.023912703784220894\n",
      "0.02249596050707408\n",
      "0.022324507008638805\n",
      "0.0217842783608973\n",
      "0.02050630694317104\n",
      "0.020421130112159944\n",
      "0.0182527146368567\n",
      "0.017144370989120007\n",
      "0.017397619321596152\n",
      "0.015469826056746884\n",
      "0.014502701404449855\n",
      "0.014557957185843072\n",
      "0.014372849218339388\n",
      "0.012363030153802497\n",
      "0.0121644436910565\n",
      "0.012518997955541587\n",
      "0.010989537943600115\n",
      "0.009850981789596069\n",
      "0.010217403288978305\n",
      "0.008694047369129435\n",
      "0.007003290848027492\n",
      "0.006187256222977535\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean of each channel for normalization\n",
    "MEAN_ARRAY = np.ndarray(shape=(BAND,),dtype=float) #row vector containing the mean of each batch\n",
    "for i in range(BAND):\n",
    "    MEAN_ARRAY[i] = np.mean(input_mat[:,:,i]) # mean per band\n",
    "    print(MEAN_ARRAY[i])\n",
    "#np.transpose(input_mat, (2,0,1)).shape transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch(height_index, width_index):\n",
    "    \"\"\"\n",
    "    Returns a mean-normalized patch, the top left corner of which \n",
    "    is at (height_index, width_index)\n",
    "    \n",
    "    Inputs: \n",
    "    height_index - row index of the top left corner of the image patch\n",
    "    width_index - column index of the top left corner of the image patch\n",
    "    \n",
    "    Outputs:\n",
    "    mean_normalized_patch - mean normalized patch of size (PATCH_SIZE, PATCH_SIZE) \n",
    "    whose top left corner is at (height_index, width_index)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # creating patch slices\n",
    "    transposed_array = np.transpose(input_mat, (2,0,1))\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE) # patch size is similar to the kernel size (same equations and logic apply)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    transposed_patch = transposed_array[:,height_slice,width_slice] # include all of the tensor's depth\n",
    "    mean_normalized_patch = []\n",
    "    for i in range(transposed_patch.shape[0]): # for every band normalize patch\n",
    "        mean_normalized_patch.append(transposed_patch[i]-MEAN_ARRAY[i]) # substract the mean for every element of in the matrix\n",
    "    return np.array(mean_normalized_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain all patches and separate them by class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "CLASSES = []\n",
    "for classes in range(OUTPUT_CLASSES):\n",
    "    CLASSES.append([]) # append the number of list classes \n",
    "    \n",
    "    \n",
    "# getting patches\n",
    "\n",
    "for i in range(HEIGHT - PATCH_SIZE +1):\n",
    "    for j in range(WIDTH - PATCH_SIZE +1):\n",
    "        # the actual patch tensor\n",
    "        input_img = patch(i,j)\n",
    "        #choose the middle of the patch as classification\n",
    "        target_id = target_mat[i+int((PATCH_SIZE-1)/2),j+int((PATCH_SIZE-1)/2)]\n",
    "        if(target_id != 0): # ignore the UNKNOWN patches\n",
    "            CLASSES[target_id -1].append(input_img)\n",
    "            \n",
    "print(\"Done\")\n",
    "print(type(CLASSES[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 145, 200)\n",
      "(145, 145)\n",
      "16\n",
      "(46, 200, 21, 21)\n",
      "\n",
      "\n",
      "Class 1 contains: 46 patches\n",
      "Class 2 contains: 1378 patches\n",
      "Class 3 contains: 547 patches\n",
      "Class 4 contains: 152 patches\n",
      "Class 5 contains: 340 patches\n",
      "Class 6 contains: 730 patches\n",
      "Class 7 contains: 28 patches\n",
      "Class 8 contains: 356 patches\n",
      "Class 9 contains: 20 patches\n",
      "Class 10 contains: 843 patches\n",
      "Class 11 contains: 2245 patches\n",
      "Class 12 contains: 481 patches\n",
      "Class 13 contains: 205 patches\n",
      "Class 14 contains: 1095 patches\n",
      "Class 15 contains: 142 patches\n",
      "Class 16 contains: 93 patches\n"
     ]
    }
   ],
   "source": [
    "print(input_mat.shape)\n",
    "print(target_mat.shape)\n",
    "print(len(CLASSES))\n",
    "print(np.array(CLASSES[0]).shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "for c in range(len(CLASSES)):\n",
    "    print(\"Class %d contains: %s patches\"%(c+1,len(CLASSES[c])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract 25% from data set for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "1034\n",
      "411\n",
      "114\n",
      "255\n",
      "548\n",
      "21\n",
      "267\n",
      "15\n",
      "633\n",
      "1684\n",
      "361\n",
      "154\n",
      "822\n",
      "107\n",
      "70\n",
      "____________\n",
      "16\n",
      "2170\n",
      "____________\n",
      "(35, 200, 21, 21)\n",
      "(200, 21, 21)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(CLASSES)):\n",
    "    class_population = len(CLASSES[i])\n",
    "    split_size = int(class_population*TEST_FRAC) # getting 25% (spliting size for the test)\n",
    "    patches_class = CLASSES[i] # extracting patches from class\n",
    "    shuffle(patches_class) # shuffling patches\n",
    "    TRAIN_PATCH.append(patches_class[:-split_size]) # from 0 to (len -split_size) contains patches\n",
    "    TEST_PATCH.extend(patches_class[-split_size:]) # from split_size to len(class)-1\n",
    "    TEST_LABELS.extend(np.full(split_size,i,dtype=int)) # 0 to 15 label\n",
    "\n",
    "for c in TRAIN_PATCH:\n",
    "    print(len(c))\n",
    "print(\"____________\")\n",
    "\n",
    "print(len(TRAIN_PATCH))\n",
    "print(len(TEST_PATCH))\n",
    "print(\"____________\")\n",
    "print(np.shape(TRAIN_PATCH[0]))\n",
    "print(np.shape(TEST_PATCH[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = CLASSES[0]\n",
    "#print(int(len(x)*TEST_FRAC))\n",
    "#print(np.shape(x))\n",
    "#np.shape(x[:-int(class_population*TEST_FRAC)])\n",
    "#np.full(int(len(x)*TEST_FRAC),len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversample the classes which do not have at least COUNT patches in the training set and extract COUNT patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This methods ensures that there are at least COUNT samples for every class\n",
    "for i in range(len(TRAIN_PATCH)):\n",
    "    if(len(TRAIN_PATCH[i])<COUNT):\n",
    "        temp = TRAIN_PATCH[i]\n",
    "        for j in range(int(COUNT/len(TRAIN_PATCH[i]))):\n",
    "            shuffle(TRAIN_PATCH[i])\n",
    "            TRAIN_PATCH[i] = TRAIN_PATCH[i]+temp # adding oversamples to the TRAININ_PATCH\n",
    "    shuffle(TRAIN_PATCH[i])\n",
    "    TRAIN_PATCH[i] = TRAIN_PATCH[i][:COUNT] # include all new oversamples of at most COUNT\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# Checking the code from above\n",
    "for c in range(len(TRAIN_PATCH)):\n",
    "    print(len(TRAIN_PATCH[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 200, 200, 21, 21)\n",
      "(3200, 200, 21, 21)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATCH = np.asarray(TRAIN_PATCH)\n",
    "print(np.shape(TRAIN_PATCH))\n",
    "TRAIN_PATCH = TRAIN_PATCH.reshape((-1,200,PATCH_SIZE,PATCH_SIZE)) # reduce dimension of the training tensor\n",
    "print(np.shape(TRAIN_PATCH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of training labels is: 3200\n",
      "The length of testing labels is: 2170\n"
     ]
    }
   ],
   "source": [
    "TRAINING_LABELS = np.array([])\n",
    "for i in range(OUTPUT_CLASSES):\n",
    "    TRAINING_LABELS = np.append(TRAINING_LABELS,np.full(COUNT,i,dtype=int))\n",
    "print(\"The length of training labels is: %d\"%len(TRAINING_LABELS))\n",
    "print(\"The length of testing labels is: %d\"%len(TEST_LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "[15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15.]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "l_train = int(len(TRAIN_PATCH)/(COUNT)) # 32000/200\n",
    "l_testing = int(len(TEST_PATCH)/(COUNT))\n",
    "for i in range(l_train):\n",
    "    train_dict ={}\n",
    "    start = i*COUNT\n",
    "    end = (i+1)*COUNT\n",
    "    train_dict[\"train_patches\"] = TRAIN_PATCH[start:end]\n",
    "    train_dict[\"train_labels\"] = TRAINING_LABELS[start:end]\n",
    "    file_name = \"Training(%s)_class(%d).mat\"%(str(PATCH_SIZE),i)\n",
    "    print(len(TRAINING_LABELS[start:end]))\n",
    "    scipy.io.savemat(os.path.join(NEW_DATA_PATH,file_name),train_dict)\n",
    "\n",
    "for i in range(l_testing):\n",
    "    test_dict = {}\n",
    "    start = i*COUNT\n",
    "    end = (i+1)*COUNT\n",
    "    test_dict[\"testing_patches\"] = TEST_PATCH[start:end]\n",
    "    test_dict[\"testing_labels\"] = TEST_LABELS[start:end]\n",
    "    file_name = \"Testing(%s)_class(%d).mat\"%(str(PATCH_SIZE),i)\n",
    "    scipy.io.savemat(os.path.join(NEW_DATA_PATH,file_name),test_dict)\n",
    "print(train_dict[\"train_labels\"])\n",
    "print('Done')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "10\n",
      "(200, 200, 21, 21)\n",
      "(200,)\n",
      "(3200,)\n",
      "[ 0.  0.  0. ... 15. 15. 15.]\n"
     ]
    }
   ],
   "source": [
    "print(l_train)\n",
    "print(l_testing)\n",
    "print(np.shape(train_dict[\"train_patches\"]))\n",
    "print(np.shape(train_dict[\"train_labels\"]))\n",
    "print(np.shape(TRAINING_LABELS))\n",
    "print(TRAINING_LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200, 21, 21)\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "list_of_dicts = []\n",
    "for files in os.listdir(NEW_DATA_PATH):\n",
    "    temp = scipy.io.loadmat(os.path.join(NEW_DATA_PATH,files))\n",
    "    list_of_dicts.append(temp)\n",
    "print(np.shape(list_of_dicts[0][\"testing_patches\"]))\n",
    "print(type((list_of_dicts[0][\"testing_labels\"][0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
