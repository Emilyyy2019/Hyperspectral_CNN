{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: tensor([[-2.2852, -2.3701, -2.3718, -2.3888, -2.4036, -2.3496, -2.2624,\n",
      "         -2.1046, -2.3356, -2.1967],\n",
      "        [-2.2538, -2.3363, -2.3198, -2.3856, -2.4149, -2.2131, -2.3117,\n",
      "         -2.1386, -2.4258, -2.2640],\n",
      "        [-2.3204, -2.4190, -2.2878, -2.3541, -2.3447, -2.3508, -2.2095,\n",
      "         -2.0742, -2.4645, -2.2569],\n",
      "        [-2.2460, -2.3709, -2.2903, -2.4660, -2.4312, -2.2263, -2.2917,\n",
      "         -2.1991, -2.3573, -2.1885],\n",
      "        [-2.1918, -2.3290, -2.4032, -2.3643, -2.4201, -2.3337, -2.3775,\n",
      "         -2.0779, -2.3577, -2.2256],\n",
      "        [-2.2018, -2.3665, -2.3591, -2.4077, -2.3594, -2.2703, -2.3117,\n",
      "         -2.1353, -2.3746, -2.2734],\n",
      "        [-2.2595, -2.2957, -2.3122, -2.3859, -2.4773, -2.2062, -2.3077,\n",
      "         -2.1928, -2.3644, -2.2568],\n",
      "        [-2.2544, -2.3669, -2.3523, -2.3316, -2.3828, -2.3558, -2.2710,\n",
      "         -2.0695, -2.4696, -2.2273],\n",
      "        [-2.2654, -2.3750, -2.3281, -2.3811, -2.4091, -2.3108, -2.2799,\n",
      "         -2.1433, -2.4046, -2.1686],\n",
      "        [-2.1996, -2.3814, -2.3874, -2.3765, -2.3230, -2.4090, -2.3411,\n",
      "         -2.1397, -2.3631, -2.1536],\n",
      "        [-2.2705, -2.3606, -2.4084, -2.3580, -2.3773, -2.2915, -2.3157,\n",
      "         -2.1453, -2.3733, -2.1629],\n",
      "        [-2.3011, -2.3626, -2.3644, -2.3859, -2.3902, -2.3276, -2.2670,\n",
      "         -2.1121, -2.3743, -2.1818],\n",
      "        [-2.2651, -2.3832, -2.3133, -2.4440, -2.3470, -2.2908, -2.2848,\n",
      "         -2.1565, -2.3686, -2.2055],\n",
      "        [-2.2781, -2.3922, -2.2392, -2.3806, -2.4299, -2.3602, -2.2091,\n",
      "         -2.1545, -2.3831, -2.2388],\n",
      "        [-2.2863, -2.3244, -2.2815, -2.4611, -2.3685, -2.3000, -2.2528,\n",
      "         -2.1504, -2.4308, -2.2103],\n",
      "        [-2.2520, -2.3559, -2.3401, -2.3993, -2.3518, -2.2882, -2.3045,\n",
      "         -2.1273, -2.4326, -2.2120],\n",
      "        [-2.2750, -2.3131, -2.3923, -2.3361, -2.4666, -2.2709, -2.3358,\n",
      "         -2.1049, -2.3982, -2.1842],\n",
      "        [-2.2878, -2.3543, -2.4255, -2.3297, -2.3203, -2.4106, -2.2684,\n",
      "         -2.0843, -2.3799, -2.2132],\n",
      "        [-2.2968, -2.4205, -2.3324, -2.3244, -2.4524, -2.2416, -2.2652,\n",
      "         -2.1833, -2.2890, -2.2498],\n",
      "        [-2.2361, -2.2530, -2.4122, -2.4328, -2.2301, -2.3979, -2.2562,\n",
      "         -2.1476, -2.3845, -2.3172],\n",
      "        [-2.2716, -2.3832, -2.2890, -2.4399, -2.3690, -2.2724, -2.3149,\n",
      "         -2.1319, -2.4064, -2.1902],\n",
      "        [-2.3145, -2.3600, -2.4423, -2.3518, -2.2486, -2.4413, -2.2859,\n",
      "         -2.0866, -2.3573, -2.1933],\n",
      "        [-2.2925, -2.3160, -2.3699, -2.3894, -2.3837, -2.3280, -2.2629,\n",
      "         -2.1226, -2.4313, -2.1738],\n",
      "        [-2.2613, -2.3916, -2.2831, -2.4456, -2.3677, -2.2977, -2.2865,\n",
      "         -2.1125, -2.4681, -2.1701],\n",
      "        [-2.2570, -2.3804, -2.3388, -2.3991, -2.4010, -2.3511, -2.2771,\n",
      "         -2.1529, -2.3598, -2.1497],\n",
      "        [-2.2816, -2.3426, -2.3387, -2.4100, -2.3341, -2.2920, -2.2808,\n",
      "         -2.1879, -2.4412, -2.1529],\n",
      "        [-2.3323, -2.2519, -2.4037, -2.3965, -2.4376, -2.2908, -2.3179,\n",
      "         -2.0641, -2.4030, -2.1902],\n",
      "        [-2.3072, -2.3435, -2.3766, -2.4005, -2.3586, -2.4404, -2.2240,\n",
      "         -2.0795, -2.4337, -2.1339],\n",
      "        [-2.2755, -2.3373, -2.4337, -2.3270, -2.3584, -2.3471, -2.2986,\n",
      "         -2.0726, -2.4582, -2.1778],\n",
      "        [-2.2648, -2.3016, -2.3451, -2.4193, -2.4270, -2.2483, -2.3756,\n",
      "         -2.0903, -2.3752, -2.2280],\n",
      "        [-2.2367, -2.4004, -2.2950, -2.3943, -2.3899, -2.2687, -2.3030,\n",
      "         -2.1478, -2.4102, -2.2171],\n",
      "        [-2.2696, -2.3324, -2.4156, -2.3386, -2.4020, -2.2244, -2.2933,\n",
      "         -2.1953, -2.3401, -2.2389]])\n",
      "Torch max : tensor([ 7,  7,  7,  9,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  9,  9,  7,  7,\n",
      "         7,  7,  7,  7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "\n",
    "# CNN class\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
    "        self.conv2_drop = nn.Dropout2d() # Dropout ensemble\n",
    "        self.fc1 = nn.Linear(320, 50) # Affine Layer\n",
    "        self.fc2 = nn.Linear(50, 10) # Affine Layer\n",
    "\n",
    "\n",
    "\n",
    "#forward method\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320) # convert into a 1x320 row vector (vectorize the tensor)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "    def name(self):\n",
    "        return \"CNN\"\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root): # if path does not exist => create path\n",
    "    os.mkdir(root)\n",
    "batch_size = 32 # batch size usually are size of powers of 2\n",
    "#transformations applied to the data\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "#training set with their respective \n",
    "train_set = datasets.MNIST(root=root,train=True,transform =trans,download=True)\n",
    "test_set = datasets.MNIST(root=root,train=False,transform =trans,download=True)\n",
    "\n",
    "#train loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "#test loader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)\n",
    "\n",
    "\n",
    "cnn = CNN() #our model\n",
    "(x,target) = iter(train_loader).next()\n",
    "output = cnn(x) # forward\n",
    "print(\"Raw output: %s\" %output.data)\n",
    "_,val  = torch.max(output.data,1)\n",
    "\n",
    "print(\"Torch max : %s\"  %val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
